{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on emotions from audio recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T20:36:00.973814Z",
     "start_time": "2020-06-22T20:35:57.269254Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import librosa\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from public datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RAVDESS\n",
    "* * 1440 files; 24 actors(12 males, 12 females);\n",
    "* TESS\n",
    "* * \"2800 files from TESS. A set of 200 target words were spoken in the carrier phrase \"Say the word _____' by two actresses (aged 26 and 64 years) and recordings were made of the set portraying each of seven emotions (anger, disgust, fear, happiness, pleasant surprise, sadness, and neutral). There are 2800 stimuli in total. Two actresses were recruited from the Toronto area. Both actresses speak English as their first language, are university educated, and have musical training. Audiometric testing indicated that both actresses have thresholds within the normal range\"\n",
    "* CREMA-D\n",
    "* * \"7,442 original clips from 91 actors. These clips were from 48 male and 43 female actors between the ages of 20 and 74 coming from a variety of races and ethnicities (African America, Asian, Caucasian, Hispanic, and Unspecified). Actors spoke from a selection of 12 sentences. The sentences were presented using one of six different emotions (Anger, Disgust, Fear, Happy, Neutral, and Sad) and four different emotion levels (Low, Medium, High, and Unspecified).\"\n",
    "* SAVEE\n",
    "* * 4 speakers; all males; anger, disgust, fear, happiness, sadness and surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T22:05:09.700958Z",
     "start_time": "2020-06-22T22:05:09.660385Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_librosa_features(dir_path, return_names=False, prefix='features_'):\n",
    "    '''Creates features matrix (76 features x N time windows) for each audio file in the directory path\\\n",
    "    Input: \n",
    "    dir_path: Path of directory containing audio files\n",
    "    \n",
    "    Output: None\n",
    "    Feature files are written to the same directory path'''\n",
    "    files = [\n",
    "        i for i in os.listdir(dir_path)\n",
    "        if os.path.isfile(os.path.join(dir_path, i)) & i.endswith('.wav')\n",
    "    ]\n",
    "    ii = 1\n",
    "    feature_names = ['mfcc' + str(i) for i in np.arange(40)] + [\n",
    "                     'delta_mfcc' + str(i) for i in np.arange(40)\n",
    "                ] + ['delta_delta_mfcc' + str(i) for i in np.arange(40)] + [\n",
    "                     'poly' + str(i) for i in np.arange(11)] + [\n",
    "                     'spectral_bw', 'spectral_centroid'\n",
    "                ] + ['spectral_cnst' + str(i) for i in np.arange(7)\n",
    "                ] + ['spectral_flat', 'spectral_rolloff', 'rms', 'zcr']\n",
    "\n",
    "    for recordingname in files:\n",
    "        if ii % 100 == 0:\n",
    "            print(ii)\n",
    "        filename_read = os.path.join(dir_path, recordingname)\n",
    "        y, sr = librosa.load(filename_read)\n",
    "        mfcc = librosa.feature.mfcc(y=y, n_mfcc=40)\n",
    "        delta_mfcc = librosa.feature.delta(mfcc)\n",
    "        features = np.vstack([\n",
    "            mfcc,  #40x\n",
    "            delta_mfcc,  #40x  \n",
    "            librosa.feature.delta(delta_mfcc),  #40x\n",
    "            librosa.feature.poly_features(y=y, order=10),  #11x\n",
    "            librosa.feature.spectral_bandwidth(y=y),  #1x\n",
    "            librosa.feature.spectral_centroid(y=y),  #1x\n",
    "            librosa.feature.spectral_contrast(y=y),  #7x\n",
    "            librosa.feature.spectral_flatness(y=y),  #1\n",
    "            librosa.feature.spectral_rolloff(y=y),  #1\n",
    "            librosa.feature.rms(y=y),  #1\n",
    "            librosa.feature.zero_crossing_rate(y=y),  #1x\n",
    "        ]),\n",
    "        ii += 1\n",
    "        np.savetxt(os.path.join(dir_path,\n",
    "                                prefix + recordingname + '.csv.gz'),\n",
    "                   features[0],\n",
    "                   delimiter=',')\n",
    "        os.remove(filename_read)\n",
    "    if return_names:\n",
    "        return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T20:52:26.488898Z",
     "start_time": "2020-06-22T20:43:26.887793Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_names = create_librosa_features('../data/SAVEE/', return_names=True)\n",
    "create_librosa_features('../data/TESS')\n",
    "create_librosa_features('../data/RAVDESS')\n",
    "create_librosa_features('../data/CREMA_D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data: https://github.com/marcogdepinto/emotion-classification-from-audio-files\n",
    "1440 samples, 24 people (50/50 M:F) at different intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:13:53.868806Z",
     "start_time": "2020-06-22T21:13:53.845170Z"
    }
   },
   "outputs": [],
   "source": [
    "metadata_ravdess = pd.read_csv(\n",
    "    '../data/ravdess_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:13:54.816734Z",
     "start_time": "2020-06-22T21:13:54.791098Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_dict = {\n",
    "    'ANG': 'angry',\n",
    "    'HAP': 'happy',\n",
    "    'SAD': 'sad',\n",
    "    'NEU': 'neutral',\n",
    "    'DIS': 'disgust',\n",
    "    'FEA': 'fearful',\n",
    "    'CAL': 'calm',\n",
    "    'SUR': 'surprise',\n",
    "    'ps': 'surprise',\n",
    "    'fear': 'fearful',\n",
    "    'f': 'fearful',\n",
    "    'h': 'happy',\n",
    "    'n': 'neutral',\n",
    "    'sa': 'sad',\n",
    "    'su': 'surprise',\n",
    "    'a': 'angry',\n",
    "    'd': 'disgust'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAVDESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:13:56.443754Z",
     "start_time": "2020-06-22T21:13:56.361485Z"
    }
   },
   "outputs": [],
   "source": [
    "# read metadata files\n",
    "metadata_ravdess = pd.read_csv(\n",
    "    '../data/ravdess_metadata.csv')\n",
    "# add sex information\n",
    "metadata_ravdess['Sex'] = metadata_ravdess.Filename.apply(\n",
    "    lambda x: \"Female\"\n",
    "    if int(x.split('-')[-1].split('.')[0]) % 2 == 0 else \"Male\")\n",
    "# add filename as feature\n",
    "metadata_ravdess['feature_filename'] = metadata_ravdess['Filename'].apply(\n",
    "    lambda x: 'features0622_' + x + '.csv.gz')\n",
    "# add path where file exists\n",
    "metadata_ravdess[\n",
    "    'directory'] = '../data/RAVDESS/'\n",
    "# lowercase emotion labesl\n",
    "metadata_ravdess.Emotion = [i.lower() for i in metadata_ravdess.Emotion]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREMA_D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:25:12.286391Z",
     "start_time": "2020-06-22T21:25:11.993541Z"
    }
   },
   "outputs": [],
   "source": [
    "# read file\n",
    "metadata_crema = pd.read_csv(\n",
    "    '../data/crema_metadata.csv')\n",
    "\n",
    "# list of audio files in dataset\n",
    "files = os.listdir('../datasets/CREMA_D/')\n",
    "Actor = []\n",
    "Statement = []\n",
    "Emotion = []\n",
    "Intensity = []\n",
    "\n",
    "# Intensity of expression\n",
    "intensity_dict = {\n",
    "    'LO': 'Low',\n",
    "    'MD': 'Normal',\n",
    "    'HI': 'Strong',\n",
    "    'XX': 'Unspecified',\n",
    "    'X': 'Unspecified',\n",
    "}\n",
    "\n",
    "for i in files:\n",
    "    split_i = i.split('_')\n",
    "    _, pid, sentence, mood, ity = split_i\n",
    "    Actor += [pid]\n",
    "    Statement += [sentence]\n",
    "    Emotion += [emotion_dict[mood]]\n",
    "    Intensity += [intensity_dict[ity.split('.')[0]]]\n",
    "\n",
    "metadata_crema2 = pd.DataFrame(\n",
    "    data={\n",
    "        'Actor': Actor,\n",
    "        'Statement': Statement,\n",
    "        'Emotion': Emotion,\n",
    "        'Intensity': Intensity,\n",
    "        'feature_filename': files\n",
    "    })\n",
    "metadata_crema2['directory'] = '../datasets/CREMA_D/'\n",
    "\n",
    "metadata_crema['ActorID'] = pd.Series(metadata_crema['ActorID'], dtype=str)\n",
    "metadata_crema = metadata_crema2.merge(metadata_crema,\n",
    "                                       left_on='Actor',\n",
    "                                       right_on='ActorID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVEE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:14:02.651972Z",
     "start_time": "2020-06-22T21:14:02.622180Z"
    }
   },
   "outputs": [],
   "source": [
    "Actor = []\n",
    "Emotion = []\n",
    "Statement = []\n",
    "dir_path = '../data/SAVEE/'\n",
    "files = os.listdir(dir_path)\n",
    "for i in files:\n",
    "    split_i = i.split('_')[1:]\n",
    "    Actor += [split_i[0]]\n",
    "    Emotion +=[emotion_dict[re.sub('\\d+','',split_i[1].split('.')[0])]]\n",
    "    Statement +=[re.sub('[a-zA-Z]','',split_i[1].split('.')[0])]\n",
    "\n",
    "metadata_savee = pd.DataFrame(data={'Actor':Actor,\n",
    "                                   'Emotion':Emotion,\n",
    "                                   'directory':dir_path,\n",
    "                                    'Statement': Statement,\n",
    "                                   'feature_filename':files})\n",
    "metadata_savee['Sex']='Male'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:16:57.580964Z",
     "start_time": "2020-06-22T21:16:57.446672Z"
    }
   },
   "outputs": [],
   "source": [
    "## TESS Dataset\n",
    "Emotion = []\n",
    "dir_path = '../data/TESS/'\n",
    "Actor = []\n",
    "Statement = []\n",
    "files = [i for i in os.listdir(dir_path) if os.path.isfile(os.path.join(dir_path, i))]\n",
    "for i in files:\n",
    "    split_i = i.split('_')\n",
    "    Statement += [split_i[2]]\n",
    "    Actor += [split_i[1]]\n",
    "    split_i = split_i[3].split('.')[0]\n",
    "    if split_i in emotion_dict:\n",
    "        split_i = emotion_dict[split_i]\n",
    "    Emotion +=[split_i]\n",
    "\n",
    "metadata_tess = pd.DataFrame(data={'Actor':Actor,\n",
    "                                   'Emotion':Emotion,\n",
    "                                   'Statement': Statement,\n",
    "                                   'directory':dir_path,\n",
    "                                   'feature_filename':files})\n",
    "metadata_tess['Sex'] = 'Female'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:25:19.328660Z",
     "start_time": "2020-06-22T21:25:19.184528Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine metadata objects\n",
    "df_metadata = pd.concat([metadata_crema, metadata_ravdess, metadata_tess, metadata_savee])\n",
    "df_metadata = df_metadata.drop(columns=['Filename','Modality','Channel','Repetition', 'ActorID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:25:34.012469Z",
     "start_time": "2020-06-22T21:25:33.800596Z"
    }
   },
   "outputs": [],
   "source": [
    "# write CSV\n",
    "df_metadata.to_csv('../data/trainingdata_metadata0622.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:25:25.936234Z",
     "start_time": "2020-06-22T21:25:25.797519Z"
    }
   },
   "outputs": [],
   "source": [
    "# read metadata CSV for 4 training datasets\n",
    "# df_metadata = pd.read_csv('../data/trainingdata_metadata0622.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:26:07.803264Z",
     "start_time": "2020-06-22T21:26:07.758432Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_summary_matrix(df,\n",
    "                          feature_names,\n",
    "                          feature_filename='feature_filename',\n",
    "                          directory='directory'):\n",
    "    '''Returns 2-D summary statistics matrix from 3-D features\n",
    "    df: dataframe containing filenames for the 3-D features matrices\n",
    "    feature_filename: df column name where 3-D features filenames are stored\n",
    "    directory: df column name for the directory path where 3-D features files are stored\n",
    "    \n",
    "    merged_df: returned 2-D matrix with Samples on 1-dim and summary features on 2-dim'''\n",
    "    feature_size = 0\n",
    "    median_arr = []  #np.zeros(56)\n",
    "    max_arr = []  #np.zeros(56)\n",
    "    min_arr = []  #np.zeros(56)\n",
    "    var_arr = []  #np.zeros(56)\n",
    "    fnames = []\n",
    "    ii = 0\n",
    "    for index, row in df_metadata.iterrows():\n",
    "        if ii % 3000 == 0:\n",
    "            print(ii)\n",
    "        fnames += [row['feature_filename']]\n",
    "        recordingname = row['directory'] + row['feature_filename']\n",
    "        x = np.loadtxt(recordingname, delimiter=',')\n",
    "        if ii == 0:\n",
    "            feature_size = x.shape[0]\n",
    "            median_arr = np.zeros(feature_size)\n",
    "            max_arr = np.zeros(feature_size)\n",
    "            min_arr = np.zeros(feature_size)\n",
    "            var_arr = np.zeros(feature_size)\n",
    "\n",
    "        median_arr = np.vstack([median_arr, np.median(x, axis=1)])\n",
    "        min_arr = np.vstack([min_arr, np.min(x, axis=1)])\n",
    "        max_arr = np.vstack([max_arr, np.max(x, axis=1)])\n",
    "        var_arr = np.vstack([var_arr, np.var(x, axis=1)])\n",
    "        ii += 1\n",
    "\n",
    "    median_arr = median_arr[1:, :]\n",
    "    min_arr = min_arr[1:, :]\n",
    "    max_arr = max_arr[1:, :]\n",
    "    var_arr = var_arr[1:, :]\n",
    "\n",
    "    merged_df = pd.DataFrame(np.hstack([median_arr, min_arr, max_arr,\n",
    "                                        var_arr]))\n",
    "\n",
    "    all_feature_names = []\n",
    "\n",
    "    for j in ['median', 'min', 'max', 'var']:\n",
    "        all_feature_names += [str.join('_', [j, i]) for i in feature_names]\n",
    "\n",
    "    assert (len(all_feature_names) == (feature_size * 4))\n",
    "    merged_df.columns = all_feature_names\n",
    "    merged_df[feature_filename] = fnames\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:35:36.660331Z",
     "start_time": "2020-06-22T21:26:09.316369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3000\n",
      "6000\n",
      "9000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "# ordered feature names\n",
    "merged_df = create_summary_matrix(df_metadata, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:35:40.366504Z",
     "start_time": "2020-06-22T21:35:40.105917Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding metadata to summary features\n",
    "training_sum_df = merged_df.merge(df_metadata, left_on='feature_filename',right_on='feature_filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T21:35:57.990542Z",
     "start_time": "2020-06-22T21:35:42.127428Z"
    }
   },
   "outputs": [],
   "source": [
    "training_sum_df.to_csv('../data/training_summary_data0622.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "358px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
